#!/usr/bin/env python3
"""
analyze_posts.py - Analyse les posts Facebook extraits pour trouver des opportunit√©s

Lit les fichiers JSON extraits par l'extension Chrome et filtre les posts
contenant des mots-cl√©s pertinents pour identifier des freelances/cr√©ateurs.
"""

import json
import sys
import os
import re
from pathlib import Path
from datetime import datetime
from typing import Optional

# Mots-cl√©s √† rechercher
KEYWORDS = [
    # Fran√ßais - M√©dias
    "photographe",
    "vid√©aste",
    "vid√©o",
    "montage",
    "r√©seaux sociaux",
    "cr√©atif",
    "contenu",
    "freelance",
    "ind√©pendant",
    # English - Media
    "photographer",
    "videographer",
    "video editor",
    "editing",
    "social media",
    "creative",
    "content creator",
    "content creation",
    # Tech/AI (attention: "ai" seul matche "j'ai" en fran√ßais!)
    "intelligence artificielle",
    "artificial intelligence",
    " IA ",          # IA avec espaces pour √©viter "j'ai", "avait", etc.
    "chatgpt",
    "automatisation",
    "automation",
    # Domaines
    "marketing",
    "branding",
    "design",
    "graphiste",
    "motion",
    "animation",
    "community manager",
    "gestionnaire de communaut√©",
    "strat√©gie digitale",
    "digital strategy",
]

# Couleurs ANSI pour le terminal
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'


def find_latest_json(tmp_dir: Path) -> Optional[Path]:
    """Trouve le fichier JSON le plus r√©cent dans .tmp/"""
    json_files = list(tmp_dir.glob("facebook_posts_*.json"))
    
    if not json_files:
        return None
    
    # Trier par date de modification (plus r√©cent en premier)
    json_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return json_files[0]


def load_posts(file_path: Path) -> dict:
    """Charge les posts depuis un fichier JSON"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def find_keywords_in_text(text: str, keywords: list) -> list:
    """Trouve tous les mots-cl√©s pr√©sents dans le texte"""
    if not text:
        return []
    
    # Ajouter des espaces au d√©but et fin pour matcher " IA "
    text_with_spaces = f" {text} "
    text_lower = text_with_spaces.lower()
    found = []
    
    for keyword in keywords:
        keyword_lower = keyword.lower()
        
        # Cas sp√©cial: " IA " - chercher exactement avec espaces (case insensitive mais mot isol√©)
        if keyword.strip() == "IA":
            # Chercher IA comme mot isol√©, pas dans "j'ai", "avait", etc.
            if re.search(r'[^a-z√©√®√™√´]ia[^a-z√©√®√™√´]', text_lower):
                # V√©rifier que ce n'est pas "j'ai" ou similaire
                if not re.search(r"[jntl]'ia", text_lower):
                    found.append("IA")
            continue
        
        # Cas normal: utilise une regex pour matcher le mot entier
        pattern = r'\b' + re.escape(keyword_lower) + r'\b'
        if re.search(pattern, text_lower):
            found.append(keyword)
    
    return found


def analyze_posts(data: dict, keywords: list = KEYWORDS) -> list:
    """Analyse les posts et retourne ceux qui matchent les mots-cl√©s"""
    matching_posts = []
    
    for post in data.get('posts', []):
        text = post.get('text', '')
        found_keywords = find_keywords_in_text(text, keywords)
        
        if found_keywords:
            matching_posts.append({
                **post,
                'matched_keywords': found_keywords
            })
    
    return matching_posts


def highlight_keywords(text: str, keywords: list) -> str:
    """Met en surbrillance les mots-cl√©s dans le texte"""
    if not text:
        return ""
    
    for keyword in keywords:
        pattern = re.compile(r'(\b' + re.escape(keyword) + r'\b)', re.IGNORECASE)
        text = pattern.sub(f'{Colors.YELLOW}{Colors.BOLD}\\1{Colors.END}', text)
    
    return text


def truncate_text(text: str, max_length: int = 300) -> str:
    """Tronque le texte √† une longueur maximale"""
    if not text:
        return ""
    if len(text) <= max_length:
        return text
    return text[:max_length] + "..."


def print_results(matching_posts: list, data: dict):
    """Affiche les r√©sultats de mani√®re format√©e"""
    total_posts = len(data.get('posts', []))
    
    print(f"\n{Colors.HEADER}{'='*60}{Colors.END}")
    print(f"{Colors.BOLD}üìä ANALYSE DES POSTS FACEBOOK{Colors.END}")
    print(f"{Colors.HEADER}{'='*60}{Colors.END}")
    
    print(f"\n{Colors.CYAN}Groupe:{Colors.END} {data.get('groupName', 'N/A')}")
    print(f"{Colors.CYAN}Extrait le:{Colors.END} {data.get('extractedAt', 'N/A')}")
    print(f"{Colors.CYAN}Total posts:{Colors.END} {total_posts}")
    print(f"{Colors.CYAN}Posts avec mots-cl√©s:{Colors.END} {Colors.GREEN}{len(matching_posts)}{Colors.END}")
    
    if not matching_posts:
        print(f"\n{Colors.YELLOW}‚ö†Ô∏è  Aucun post ne correspond aux mots-cl√©s recherch√©s.{Colors.END}")
        return
    
    # Compter les mots-cl√©s les plus fr√©quents
    keyword_counts = {}
    for post in matching_posts:
        for kw in post.get('matched_keywords', []):
            keyword_counts[kw] = keyword_counts.get(kw, 0) + 1
    
    print(f"\n{Colors.BOLD}üè∑Ô∏è  Mots-cl√©s trouv√©s:{Colors.END}")
    for kw, count in sorted(keyword_counts.items(), key=lambda x: -x[1]):
        print(f"   ‚Ä¢ {kw}: {count} occurrences")
    
    print(f"\n{Colors.HEADER}{'='*60}{Colors.END}")
    print(f"{Colors.BOLD}üìù POSTS CORRESPONDANTS{Colors.END}")
    print(f"{Colors.HEADER}{'='*60}{Colors.END}")
    
    for i, post in enumerate(matching_posts, 1):
        print(f"\n{Colors.BLUE}‚îÅ‚îÅ‚îÅ Post #{i} ‚îÅ‚îÅ‚îÅ{Colors.END}")
        print(f"{Colors.BOLD}üë§ Auteur:{Colors.END} {post.get('author', 'Inconnu')}")
        
        if post.get('date') or post.get('dateRelative'):
            date_str = post.get('date') or post.get('dateRelative')
            print(f"{Colors.BOLD}üìÖ Date:{Colors.END} {date_str}")
        
        print(f"{Colors.BOLD}üè∑Ô∏è  Mots-cl√©s:{Colors.END} {', '.join(post.get('matched_keywords', []))}")
        
        # Afficher le texte avec mots-cl√©s en surbrillance
        text = post.get('text', '')
        highlighted = highlight_keywords(truncate_text(text, 400), post.get('matched_keywords', []))
        print(f"{Colors.BOLD}üí¨ Contenu:{Colors.END}\n   {highlighted}")
        
        if post.get('postUrl'):
            print(f"{Colors.BOLD}üîó Lien:{Colors.END} {post.get('postUrl')}")
        
        if post.get('authorProfileUrl'):
            print(f"{Colors.BOLD}üë§ Profil:{Colors.END} {post.get('authorProfileUrl')}")


def save_results(matching_posts: list, data: dict, output_path: Path):
    """Sauvegarde les r√©sultats dans un fichier JSON"""
    results = {
        'analyzedAt': datetime.now().isoformat(),
        'sourceFile': str(output_path),
        'groupName': data.get('groupName'),
        'groupUrl': data.get('groupUrl'),
        'totalPosts': len(data.get('posts', [])),
        'matchingPosts': len(matching_posts),
        'keywordsUsed': KEYWORDS,
        'posts': matching_posts
    }
    
    output_file = output_path.parent / f"analyzed_{output_path.name}"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\n{Colors.GREEN}‚úÖ R√©sultats sauvegard√©s: {output_file}{Colors.END}")
    return output_file


def main():
    # D√©terminer le dossier .tmp
    script_dir = Path(__file__).parent.parent
    tmp_dir = script_dir / '.tmp'
    
    # V√©rifier si un fichier sp√©cifique est pass√© en argument
    if len(sys.argv) > 1:
        input_file = Path(sys.argv[1])
        if not input_file.exists():
            print(f"{Colors.RED}‚ùå Fichier non trouv√©: {input_file}{Colors.END}")
            sys.exit(1)
    else:
        # Trouver le fichier JSON le plus r√©cent
        if not tmp_dir.exists():
            print(f"{Colors.RED}‚ùå Le dossier .tmp n'existe pas.{Colors.END}")
            print(f"   Cr√©ez-le et placez-y les fichiers JSON extraits.")
            sys.exit(1)
        
        input_file = find_latest_json(tmp_dir)
        if not input_file:
            print(f"{Colors.RED}‚ùå Aucun fichier facebook_posts_*.json trouv√© dans .tmp/{Colors.END}")
            print(f"   Utilisez l'extension Chrome pour extraire des posts.")
            sys.exit(1)
    
    print(f"{Colors.CYAN}üìÇ Analyse du fichier: {input_file}{Colors.END}")
    
    # Charger et analyser
    data = load_posts(input_file)
    matching_posts = analyze_posts(data)
    
    # Afficher les r√©sultats
    print_results(matching_posts, data)
    
    # Sauvegarder les r√©sultats
    if matching_posts:
        save_results(matching_posts, data, input_file)


if __name__ == '__main__':
    main()

